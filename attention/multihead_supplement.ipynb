{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2345c19d-4998-4978-9514-f15bf0200140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682d8d94-9e4f-4a60-a8e0-2759ed4afe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1 start with the input \n",
    "# b ,num_of_tokens, d_in = (1,3,6) -> batch =1, number of token =3, embedding dimension = 6\n",
    "d_in = 6\n",
    "x = torch.tensor([[[1.0,2.0,3.0,4.0,5.0,6.0],   #the\n",
    "                   [6.0,5.0,4.0,3.0,2.0,1.0],   #cat\n",
    "                   [1.0,1.0,1.0,1.0,1.0,1.0]]]) #sleeps\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1889c0-6d20-42d4-89bf-cd254cd09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: decide d_out, number of heads  \n",
    "d_out = 6   #for dimension of context vector if dout =6 then dimension of context vector = 3 x 6  \n",
    "# number of attn heads = 2 \n",
    "num_heads = 2\n",
    "# Given this head_dim = 6/2 = 3 -> so each head has a dimension 3  \n",
    "head_dim = d_out//num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2090e7-1ffb-4155-be1d-2ef094f0fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the weight matrices for key query and value\n",
    "# 6 x 6  \n",
    "import torch.nn as nn\n",
    "W_query = nn.Linear(d_in,d_out, bias=False)\n",
    "W_key = nn.Linear(d_in, d_out, bias=False)\n",
    "W_value = nn.Linear(d_in, d_out, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f74879c-483b-4ff7-bafe-b624eb231c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query weight matrix:\n",
      "tensor([[ 0.0994, -0.3706,  0.2431,  0.2046,  0.1399,  0.3392],\n",
      "        [-0.0107, -0.0927,  0.2060,  0.1684,  0.2498, -0.2904],\n",
      "        [ 0.3014,  0.1254,  0.1257,  0.1717,  0.0955, -0.2667],\n",
      "        [-0.3731,  0.3828, -0.3635, -0.3155,  0.1172, -0.0590],\n",
      "        [-0.2768, -0.0638,  0.1943, -0.2806,  0.2499,  0.1582],\n",
      "        [-0.2427, -0.1134, -0.0316, -0.0958, -0.2733,  0.1731]])\n",
      "\n",
      "W_key weight matrix:\n",
      "tensor([[ 0.1453,  0.2993,  0.3894,  0.0725, -0.3739,  0.1844],\n",
      "        [-0.1958, -0.2417, -0.2086,  0.0361,  0.2955, -0.2080],\n",
      "        [-0.3570,  0.3868,  0.1560, -0.3431,  0.3903,  0.0418],\n",
      "        [ 0.2738,  0.3491, -0.1222, -0.2679,  0.3618, -0.0428],\n",
      "        [-0.4038, -0.0402, -0.1200,  0.2469, -0.1900, -0.1259],\n",
      "        [-0.0832, -0.2505,  0.3393, -0.2988,  0.0803, -0.3066]])\n",
      "\n",
      "W_value weight matrix:\n",
      "tensor([[ 0.3367, -0.3055,  0.0278,  0.3592,  0.3428, -0.0699],\n",
      "        [-0.0987, -0.0080,  0.3444,  0.3132,  0.2908, -0.3063],\n",
      "        [-0.3165,  0.1133, -0.3813, -0.1021, -0.3476, -0.1993],\n",
      "        [-0.0786,  0.1754, -0.2032,  0.2826, -0.3251,  0.1958],\n",
      "        [-0.3243, -0.0142, -0.3495, -0.0513,  0.0616, -0.0366],\n",
      "        [-0.3894, -0.2348,  0.2438, -0.0751, -0.2598, -0.0210]])\n"
     ]
    }
   ],
   "source": [
    "# Print the values of the weight matrices\n",
    "print(\"W_query weight matrix:\")\n",
    "print(W_query.weight.data)# Access the underlying data of the tensor\n",
    "\n",
    "print(\"\\nW_key weight matrix:\")\n",
    "print(W_key.weight.data)\n",
    "\n",
    "print(\"\\nW_value weight matrix:\")\n",
    "print(W_value.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f6284a-5ad3-46c0-b8be-dbdc063aaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get queries, keys and value matrices\n",
    "# Apply the linear transformations\n",
    "queries = W_query(x)\n",
    "keys = W_key(x)\n",
    "values = W_value(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721774fc-98bd-458d-81ae-8199de4d9960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.6407,  0.6016,  0.4935, -1.7284,  1.2552, -1.2758],\n",
      "         [ 0.9491,  1.0102,  3.3780, -2.5499, -1.3864, -2.8108],\n",
      "         [ 0.6557,  0.2303,  0.5531, -0.6112, -0.0187, -0.5838]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(queries)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f91a819-fe68-4cc5-aab7-1a923d7b5ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4392, -0.9314,  1.7147,  1.0859, -1.5617, -2.1994],\n",
      "         [ 3.5801, -2.7269,  0.2090,  2.7768, -2.8686, -1.4366],\n",
      "         [ 0.7170, -0.5226,  0.2748,  0.5518, -0.6329, -0.5194]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(keys)\n",
    "print(keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a265ac35-a92b-40cf-9e77-beef64d62824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.5402,  1.7876, -4.5756,  0.3422, -1.5177, -1.8528],\n",
      "         [ 2.2967,  1.9605, -4.0580, -0.0142, -3.4818, -3.3014],\n",
      "         [ 0.6910,  0.5354, -1.2334,  0.0469, -0.7142, -0.7363]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(values)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5083d49-6b7f-4b41-8ac9-e70a5ecd92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: We implicitly split the matrix by adding a num_heads dimension. \n",
    "# Unroll the last dimension for keys, queries and dimension to include the num of heads and head dimension\n",
    "#head_dim = d_out/num_heads = 6/2 = 3\n",
    "# (b=1, num_of_token= 3, dout = 6) -> (b=1, num_tokens= 3, num_head =2, head_dim = 3)\n",
    "# (1,3,6) -> (1,3,2,3)\n",
    "# Reshape the tensors to (1, 3, 2, head_dim)\n",
    "reshaped_Q = queries.reshape(1, 3, 2, head_dim)\n",
    "reshaped_K = keys.reshape(1, 3, 2, head_dim)\n",
    "reshaped_V = values.reshape(1, 3, 2, head_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e277f21-5254-4da2-a891-8d9018353724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.6407,  0.6016,  0.4935],\n",
      "          [-1.7284,  1.2552, -1.2758]],\n",
      "\n",
      "         [[ 0.9491,  1.0102,  3.3780],\n",
      "          [-2.5499, -1.3864, -2.8108]],\n",
      "\n",
      "         [[ 0.6557,  0.2303,  0.5531],\n",
      "          [-0.6112, -0.0187, -0.5838]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(reshaped_Q)  #(batch, num of tokens, number of heads, head dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f067ca-730b-4571-86bd-30fe147f3582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4392, -0.9314,  1.7147],\n",
      "          [ 1.0859, -1.5617, -2.1994]],\n",
      "\n",
      "         [[ 3.5801, -2.7269,  0.2090],\n",
      "          [ 2.7768, -2.8686, -1.4366]],\n",
      "\n",
      "         [[ 0.7170, -0.5226,  0.2748],\n",
      "          [ 0.5518, -0.6329, -0.5194]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(reshaped_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3d46f0-a2de-4600-a100-9e1de0224bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5402,  1.7876, -4.5756],\n",
      "          [ 0.3422, -1.5177, -1.8528]],\n",
      "\n",
      "         [[ 2.2967,  1.9605, -4.0580],\n",
      "          [-0.0142, -3.4818, -3.3014]],\n",
      "\n",
      "         [[ 0.6910,  0.5354, -1.2334],\n",
      "          [ 0.0469, -0.7142, -0.7363]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(reshaped_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "284f4397-e23b-4232-a500-9d7141d69b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Transpose from shape (b, num_tokens, num_heads, head_dim) to (b, num_heads, num_tokens, head_dim)\n",
    "#matrices grouped according to token\n",
    "# we want to group by number of head\n",
    "# (batch = 1, number of tokens = 3, number of heads = 2, head_dim = 3 ) -> ( batch =1, number of heads =2, number of tokens = 3, head_dim =3)\n",
    "#(1,3,2,3) -> (1,2,3,3)\n",
    "transposed_Q = reshaped_Q.transpose(1, 2)\n",
    "transposed_K = reshaped_K.transpose(1, 2)\n",
    "transposed_V = reshaped_V.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d186cb-1c21-4f46-8693-9c1ef838608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.6407,  0.6016,  0.4935],\n",
      "          [ 0.9491,  1.0102,  3.3780],\n",
      "          [ 0.6557,  0.2303,  0.5531]],\n",
      "\n",
      "         [[-1.7284,  1.2552, -1.2758],\n",
      "          [-2.5499, -1.3864, -2.8108],\n",
      "          [-0.6112, -0.0187, -0.5838]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(transposed_Q)\n",
    "print(transposed_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e58da59-37e1-466c-9e87-235325e418a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4392, -0.9314,  1.7147],\n",
      "          [ 3.5801, -2.7269,  0.2090],\n",
      "          [ 0.7170, -0.5226,  0.2748]],\n",
      "\n",
      "         [[ 1.0859, -1.5617, -2.1994],\n",
      "          [ 2.7768, -2.8686, -1.4366],\n",
      "          [ 0.5518, -0.6329, -0.5194]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(transposed_K)\n",
    "print(transposed_K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "790854ac-df90-40aa-871c-9f582ae86b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5402,  1.7876, -4.5756],\n",
      "          [ 2.2967,  1.9605, -4.0580],\n",
      "          [ 0.6910,  0.5354, -1.2334]],\n",
      "\n",
      "         [[ 0.3422, -1.5177, -1.8528],\n",
      "          [-0.0142, -3.4818, -3.3014],\n",
      "          [ 0.0469, -0.7142, -0.7363]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(transposed_V)\n",
    "print(transposed_V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4853932e-c4e4-4e9e-b0ed-b058dd2f7cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4392, -0.9314,  1.7147],\n",
      "          [ 3.5801, -2.7269,  0.2090],\n",
      "          [ 0.7170, -0.5226,  0.2748]],\n",
      "\n",
      "         [[ 1.0859, -1.5617, -2.1994],\n",
      "          [ 2.7768, -2.8686, -1.4366],\n",
      "          [ 0.5518, -0.6329, -0.5194]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# for ease of understanding\n",
    "queries = transposed_Q\n",
    "keys = transposed_K\n",
    "values = transposed_V\n",
    "print(keys)\n",
    "print(keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6dc5677-5778-43db-bcd2-26411f1ca5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4392,  3.5801,  0.7170],\n",
      "          [-0.9314, -2.7269, -0.5226],\n",
      "          [ 1.7147,  0.2090,  0.2748]],\n",
      "\n",
      "         [[ 1.0859,  2.7768,  0.5518],\n",
      "          [-1.5617, -2.8686, -0.6329],\n",
      "          [-2.1994, -1.4366, -0.5194]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(keys.transpose(2, 3))\n",
    "print(keys.transpose(2, 3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcabca37-75c4-44fc-9e19-990e207a5c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.6407,  0.6016,  0.4935],\n",
      "          [ 0.9491,  1.0102,  3.3780],\n",
      "          [ 0.6557,  0.2303,  0.5531]],\n",
      "\n",
      "         [[-1.7284,  1.2552, -1.2758],\n",
      "          [-2.5499, -1.3864, -2.8108],\n",
      "          [-0.6112, -0.0187, -0.5838]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(queries)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ccb06a7-682a-412e-98f5-3ae3fc3c7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now get attention scores\n",
    "# queries*keys.transpose(2,3) --> why 2,3 (b,numhead, num_tokens, head_dim)\n",
    "attn_scores = queries @ keys.transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5202d16b-ff4b-4039-ab07-65fa8a78d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.5256, 11.4966,  2.4317],\n",
      "          [ 6.2173,  1.3493,  1.0809],\n",
      "          [ 1.6776,  1.8351,  0.5018]],\n",
      "\n",
      "         [[-1.0312, -6.5674, -1.0855],\n",
      "          [ 5.5780,  0.9344,  0.9303],\n",
      "          [ 0.6496, -0.8047, -0.0222]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(attn_scores)    # attention 3x3 (the cat sleeps) for each head\n",
    "print(attn_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fc45e27-9bb8-499f-ac54-143c29ed639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Mask truncated to the number of tokens\n",
    "context_length = 3  # Or whatever your context length is\n",
    "mask = torch.triu(torch.ones(context_length, context_length),\n",
    "                  diagonal=1)\n",
    "num_tokens = 3\n",
    "mask_bool = mask.bool()[:num_tokens, :num_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08bcb3a6-4a03-4e78-86b8-91fe264ecd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.5256,    -inf,    -inf],\n",
       "          [ 6.2173,  1.3493,    -inf],\n",
       "          [ 1.6776,  1.8351,  0.5018]],\n",
       "\n",
       "         [[-1.0312,    -inf,    -inf],\n",
       "          [ 5.5780,  0.9344,    -inf],\n",
       "          [ 0.6496, -0.8047, -0.0222]]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Use the mask to fill attention scores\n",
    "attn_scores.masked_fill_(mask_bool, -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c0908c9-d72e-4f39-b68c-97f664115ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9432, 0.0568, 0.0000],\n",
      "          [0.3843, 0.4208, 0.1949]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9359, 0.0641, 0.0000],\n",
      "          [0.4738, 0.2046, 0.3215]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Softmax with variance\n",
    "print(keys.shape[-1])   #head dimension 3\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8a1ff8a-2d47-461a-8fdb-a7a47679e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u can also apply dropout after this - not shown here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de73de0e-c2ce-4968-89a7-51f032ade036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dba83c3c-fa16-4761-884e-46be90e96100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5402,  1.7876, -4.5756],\n",
      "          [ 2.2967,  1.9605, -4.0580],\n",
      "          [ 0.6910,  0.5354, -1.2334]],\n",
      "\n",
      "         [[ 0.3422, -1.5177, -1.8528],\n",
      "          [-0.0142, -3.4818, -3.3014],\n",
      "          [ 0.0469, -0.7142, -0.7363]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(values)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08896bf9-03d8-4388-8494-598c51371dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5402,  1.7876, -4.5756],\n",
      "          [ 2.5264,  1.7975, -4.5462],\n",
      "          [ 2.0773,  1.6163, -3.7064]],\n",
      "\n",
      "         [[ 0.3422, -1.5177, -1.8528],\n",
      "          [ 0.3194, -1.6436, -1.9457],\n",
      "          [ 0.1743, -1.6613, -1.7903]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Context vector ---> attn * values\n",
    "# attn -> (b, heads, num_token, num_token) - (1,2,3,3)\n",
    "# value -> (b, heads, num_token, head_dim) - (1,2,3,3)\n",
    "# after multiplication -> (b,heads, num_token, head_dim)  (3 x 3) x (3 x 3) -> 3 x 3\n",
    "# see below\n",
    "context_vec = (attn_weights @ values)\n",
    "print(context_vec)\n",
    "print(context_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a814daf-dd9a-4299-bb94-d3d3cb01f0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5402,  1.7876, -4.5756],\n",
      "          [ 0.3422, -1.5177, -1.8528]],\n",
      "\n",
      "         [[ 2.5264,  1.7975, -4.5462],\n",
      "          [ 0.3194, -1.6436, -1.9457]],\n",
      "\n",
      "         [[ 2.0773,  1.6163, -3.7064],\n",
      "          [ 0.1743, -1.6613, -1.7903]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# but we wanted to combine the heads in the output concatinated context vector output\n",
    "# basically convert (b, head, num_token, head_dim) -> (b, num_token, head, head_dim)\n",
    "# how do we do this - transpose(1,2) -> transpose(head, num_token)\n",
    "context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "print(context_vec)\n",
    "print(context_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "542bd639-cf50-4a70-b855-218a3b36a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.5402,  1.7876, -4.5756,  0.3422, -1.5177, -1.8528],\n",
      "         [ 2.5264,  1.7975, -4.5462,  0.3194, -1.6436, -1.9457],\n",
      "         [ 2.0773,  1.6163, -3.7064,  0.1743, -1.6613, -1.7903]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "# now flatten each set of token into 1 row\n",
    "# Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "b = 1,\n",
    "num_tokens = 3\n",
    "context_vec = context_vec.contiguous().view(1, 3, d_out)\n",
    "print(context_vec)\n",
    "print(context_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7d0a7-4a73-42d9-9659-d239a195e327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
